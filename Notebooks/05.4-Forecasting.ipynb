{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# 05.4 Forecasting\n",
    "\n",
    "Forecasting is the art of taking an educated guess at what future data might look like. A good forecast can inform you on several business decisions you might have to make.\n",
    "\n",
    "In several business models, forecasting can help you make informed decisions to improve person-power allocation, scheduling, or logistical decisions.\n",
    "\n",
    "When you are operating with limited information (no external pressure from current events, like pendemics, wars, volcaninc eruptions), a simple extrapolation can already offer you some clues of what is __most likely to happen__ and not __what will happen__.\n",
    "\n",
    "With the help of datetime, and if the cycles of your observable match up with a pre-defined cycle (week, month, day, year), it can be easy to produce a forecast with an __confidence interval__."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "---\n",
    "## Forecast based on past observations with cyclical behaviour\n",
    "\n",
    "Let's recover the temperature example from the previous notebook."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import numpy as np\n",
    "import matplotlib.pyplot as plt"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "pd.__version__ #make sure you have at least version 1.2"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "temp_file = 'https://raw.githubusercontent.com/jbrownlee/Datasets/master/daily-min-temperatures.csv'\n",
    "\n",
    "dtemp = pd.read_csv(temp_file)\n",
    "temp_series = dtemp.set_index('Date')\n",
    "temp_series.index = pd.to_datetime(temp_series.index)\n",
    "\n",
    "fig, ax = plt.subplots(figsize=(12,5))\n",
    "temp_series.plot(ax=ax)\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Assume we wish to do a daily average over the several years. There are many ways of doing this with pandas. We will just solve the problem by adding a column with \"day_of_year\"."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "temp_series.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "temp_series['day_of_year'] = temp_series.index.day_of_year"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "temp_series.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "temp_series.tail()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Now we need to group this dataframe into a new dataframe where the index will be the \"day_of_year\"."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "dayyeardf = temp_series.groupby(by='day_of_year').mean()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "dayyeardf.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "dayyeardf.plot()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "This can provide an average value for what we are expecting, but for a better forecast, and also to have an idea if we are encountering outliers, we should also include the Standard deviation. Let's regroup the time series again with more info."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "dayyear = temp_series.groupby(by='day_of_year').Temp.agg(['mean','std'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "dayyear"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "fig, ax = plt.subplots(figsize=(12,5))\n",
    "\n",
    "ax.fill_between(dayyear.index,\n",
    "                dayyear['mean'] - dayyear['std'],\n",
    "                dayyear['mean'] + dayyear['std'],\n",
    "                alpha=0.4)\n",
    "\n",
    "dayyear['mean'].plot(ax=ax, c='C3')\n",
    "\n",
    "ax.set_ylabel(\"Temperature [C]\")\n",
    "\n",
    "plt.title(\"Expected temperature according to day of year\", loc='left')\n",
    "plt.tight_layout()\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "---\n",
    "## Forecasting more complex observations\n",
    "\n",
    "The most common family of forecasting models are the __ARIMA: Auto-Regressive integrated Moving Average__. \n",
    "\n",
    "In the persepctive of Time-Series analysis, stationary might mean, according to who you ask:\n",
    "\n",
    "* Data with a periodic repetition only. For example, a stationary yearly model would always have the same approximate value in the same month, like the daily temperatures.\n",
    "* Data which is just a trendline. Some mechanism with no seasonality and a easy to explain trend (a linear increase of some KPI).\n",
    "\n",
    "As we've seen before, most KPIs may not have only a stationary component, meaning the standard ARIMA might not be sufficient. As we will see, there are some extensions that allow to cover most cases.\n",
    "\n",
    "The basic ARIMA function has three parameters:\n",
    "\n",
    "* __AR(p)__: Auto-Regressive term: The number of lag observations included in the model: How many past observations I consider to influence directly the next observation. \n",
    "* __I(d)__: Integrating term: The number of times that the raw observations are differenced, i.e., how many past observation can contribute to generate a baseline for the next observation.\n",
    "* __MA(q)__: Moving-Average term: Size of the moving average window, or Order of moving average.\n",
    "\n",
    "There are many combinations of values for (p, d, q). You can see a list of the [most common combinations here](https://people.duke.edu/~rnau/411arim.htm).\n",
    "\n",
    "ARIMA models can be very heavy to train when you have many observations. We will use a small dataset to exemplify."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from statsmodels.tsa.arima.model import ARIMA\n",
    "import matplotlib.pyplot as plt\n",
    "import numpy as np\n",
    "import pandas as pd"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Create a simple dataset\n",
    "npts = 100\n",
    "x = np.arange(0, npts)\n",
    "data = np.arange(0, npts) + 3*np.random.randn(npts)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# fit \n",
    "model = ARIMA(data, order=(5, 1, 1))\n",
    "model_fit = model.fit()\n",
    "\n",
    "#Make the following number of predictions\n",
    "additional_points = 10\n",
    "\n",
    "yhat = model_fit.predict(len(data), len(data)+additional_points-1, typ='levels')\n",
    "xhat = np.arange(0, additional_points) + npts + 1.0\n",
    "\n",
    "plt.plot(x, data)\n",
    "plt.plot(xhat, yhat)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "ARIMAs are nice for short term prediction. You need to keep retraining the model for new predictions as soon as you have new data, in a sliding fashion. But ARIMAs can get very complicated very fast:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "## Monthly sunspots\n",
    "chosen_file = '../Files/monthly-sunspots.csv'\n",
    "\n",
    "df = pd.read_csv(chosen_file)\n",
    "time_series = df.set_index(df.columns[0])\n",
    "time_series.index = pd.to_datetime(time_series.index)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "time_series.plot()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "npts = 2 * 11 * 12 ## Two solar cycles: 22 years\n",
    "\n",
    "train = time_series[:-npts]\n",
    "test = time_series[-npts:]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#data = time_series.values\n",
    "\n",
    "## Some warnings here is OK\n",
    "model = ARIMA(train.values, order=(1, 1, 7), dates=train.index)\n",
    "model_fit = model.fit()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#model_fit.summary()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "forecast_data =  model_fit.predict(len(train), len(train)+npts-1)\n",
    "forecast_index = test.index\n",
    "\n",
    "forecast = pd.Series(data=forecast_data, index=forecast_index)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "fig, ax = plt.subplots(figsize=(12,5))\n",
    "forecast.plot(ax=ax)\n",
    "test.plot(ax=ax)\n",
    "#plt.xlim('1962', '1966')\n",
    "##plt.ylim(0, 1000)\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Predicting the next few years gives us not such a bad result. But after a while we would need to retrain the model and re-forecast. The ARIMA family is good for the next few observations but is is very hard to tune for the long-term. ARIMA tunning is hard to understand. Currently, ARIMAs are being replaced by Neural-Network approaches, namely Convolutional Neural Netowrks (CNNs). Easier to understand, thus also easier to train. Let's see one last example with an ARIMA extension: __SARIMAX__. SARIMAX stands for Seasonal ARIMA with eXogenous factors. It is an ARIMA model enriched with a Seasonal component. The Exgoneous variety means we have to impose outside conditions on the model. It is possible, through several statistical testing, to determine the best (p,d,q) for an ARIMA. As soon as you bring outside (Exogenous) factors, you must force the model to use them, and you must get information from outside of the current observables you have."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from statsmodels.tsa.statespace.sarimax import SARIMAX"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Besides the basic ARIMA (p,d,q) parameters, the process also has Exogenous parameters (P, D, Q, m). The capital letters are relative not to the observed data's definitions, but to Outsider knowloedge we have and impose on the analysis. So the \"p\" of the data must observe the \"P\" of the mechanism that creates it. The additional parameter \"m\" refers to the number of points in the data for a seasonal cycle. In our case, it's monthly data in a yearly cycle, so we have m=12."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "airline_file = 'https://raw.githubusercontent.com/jbrownlee/Datasets/master/airline-passengers.csv'\n",
    "dair = pd.read_csv(airline_file, index_col='Month')\n",
    "dair.index = pd.to_datetime(dair.index)\n",
    "\n",
    "train = dair[:-12]\n",
    "test = dair[-12:]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "fig, ax = plt.subplots(figsize=(12,5))\n",
    "\n",
    "train.plot(ax=ax)\n",
    "test.plot(ax=ax)\n",
    "plt.legend(['Train', 'Test'])\n",
    "plt.tight_layout()\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "model = SARIMAX(train['Passengers'],\n",
    "                order = (2, 1, 1),  \n",
    "                seasonal_order =(2, 1, 1, 12))\n",
    "\n",
    "model_fit = model.fit()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "yhat = model_fit.predict(start=len(train), end=len(train)+12-1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "predictdf = pd.Series(index=test.index, data=yhat)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "fig, ax = plt.subplots(figsize=(12,5))\n",
    "\n",
    "train.plot(ax=ax, label='Train')\n",
    "test.plot(ax=ax, label='Test')\n",
    "\n",
    "predictdf.plot(ax=ax, c='C3')\n",
    "\n",
    "plt.legend(['Train', 'Test', 'Prediction'])\n",
    "plt.tight_layout()\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "The ARIMA family is hard to tune, there's why you usually train it with __brute force__."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "---\n",
    "### Auto-ARIMA\n",
    "\n",
    "Sometimes you will need to perform forecasts of very complex datasets. When the data is hard to understand, auto-ML might become a solution. It goes beyond the scope of this class, but you can have an auto-ARIMA model scanning a pre-defined parameter space for the model terms and then returning the best set of points, defined by minimizing the RMSE (root mean square error) between a test set and the output of the model."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Import auto_arima\n",
    "from pmdarima import auto_arima \n",
    "  \n",
    "# Ignore the warnings, as some parameters may be incompatible with some ARIMA settings \n",
    "import warnings \n",
    "warnings.filterwarnings(\"ignore\") \n",
    "  \n",
    "# Fit the several\n",
    "stepwise_fit = auto_arima(dair['Passengers'],\n",
    "                          start_p = 1,\n",
    "                          start_q = 1, \n",
    "                          max_p = 3,\n",
    "                          max_q = 3,\n",
    "                          m = 12, \n",
    "                          start_P = 0,\n",
    "                          seasonal = True, \n",
    "                          d = None,\n",
    "                          D = 1,\n",
    "                          trace = True, \n",
    "                          error_action ='ignore',   # Ignore incompatible settings\n",
    "                          suppress_warnings = True,  \n",
    "                          stepwise = True)           \n",
    "  \n",
    "# To print the summary \n",
    "stepwise_fit.summary() "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "prediction = pd.DataFrame(stepwise_fit.predict(n_periods = 24))#, index=dair.index)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "prediction.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "prediction['Time'] = pd.date_range(start='1961-01-01', periods=24, freq='MS')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "prediction.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "prediction.set_index('Time', inplace=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "dair"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "fig, ax = plt.subplots(figsize=(12,5))\n",
    "\n",
    "dair.plot(ax=ax, legend='Train')\n",
    "prediction.plot(ax=ax, label='Prediction')\n",
    "\n",
    "plt.legend(['Train', 'Prediction'])\n",
    "plt.tight_layout()\n",
    "plt.show()"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.11"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
